
<!doctype html>
<html lang="ja">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Webcam VO (SLAM-ish) Demo - Trajectory + Simple Map</title>
  <style>
    body { margin:0; font-family: system-ui, -apple-system, Segoe UI, Roboto, sans-serif; background:#111; color:#eee; }
    header { padding:10px 14px; background:#1a1a1a; border-bottom:1px solid #2a2a2a; }
    header b { color:#9ad; }
    .wrap { display:grid; grid-template-columns: 1fr 420px; gap:12px; padding:12px; }
    .card { background:#1a1a1a; border:1px solid #2a2a2a; border-radius:12px; padding:10px; }
    .row { display:flex; gap:10px; align-items:center; flex-wrap:wrap; }
    button { background:#2a2a2a; color:#eee; border:1px solid #3a3a3a; border-radius:10px; padding:8px 10px; cursor:pointer; }
    button:hover { background:#333; }
    label { font-size:13px; opacity:.9; display:flex; gap:8px; align-items:center; }
    input[type="range"] { width:180px; }
    small { opacity:.8; }
    canvas { width:100%; height:auto; border-radius:10px; background:#0b0b0b; }
    video { width:100%; height:auto; border-radius:10px; background:#000; display:none; }
    .status { font-size:12px; opacity:.85; white-space:pre-wrap; line-height:1.35; }
    .grid2 { display:grid; grid-template-columns: 1fr; gap:10px; }
  </style>
</head>
<body>
<header>
  <div><b>Webcam VO (SLAM-ish)</b>：軌跡 + 簡易マップ（単眼VO / OpenCV.js）</div>
  <small>単眼なのでスケール不定 / ループ閉じ無し。デモ用途向け。</small>
</header>

<div class="wrap">
  <div class="card">
    <div class="row" style="justify-content:space-between;">
      <div class="row">
        <button id="btnStart">Start</button>
        <button id="btnStop" disabled>Stop</button>
        <button id="btnReset" disabled>Reset Map</button>
      </div>
      <div class="row">
        <label>Max features
          <input id="rngFeat" type="range" min="300" max="3000" step="100" value="1200">
          <span id="lblFeat">1200</span>
        </label>
        <label>Match keep
          <input id="rngKeep" type="range" min="50" max="600" step="10" value="200">
          <span id="lblKeep">200</span>
        </label>
      </div>
    </div>

    <div class="grid2" style="margin-top:10px;">
      <video id="video" playsinline autoplay muted></video>
      <canvas id="view" width="960" height="540"></canvas>
      <div class="status" id="status">OpenCV.js loading...</div>
    </div>
  </div>

  <div class="card">
    <div style="margin-bottom:8px;"><b>Trajectory / Simple Map</b></div>
    <canvas id="map" width="400" height="400"></canvas>
    <div style="margin-top:10px;">
      <small>
        - 青：軌跡（カメラ位置）<br/>
        - 灰：簡易マップ点（“それっぽい”ポイント）<br/>
        - 原点はReset時の位置
      </small>
    </div>
  </div>
</div>

<!-- OpenCV.js (WASM) -->
<script async src="https://docs.opencv.org/4.x/opencv.js"></script>

<script>
(() => {
  // UI
  const btnStart = document.getElementById('btnStart');
  const btnStop  = document.getElementById('btnStop');
  const btnReset = document.getElementById('btnReset');
  const statusEl = document.getElementById('status');

  const rngFeat = document.getElementById('rngFeat');
  const rngKeep = document.getElementById('rngKeep');
  const lblFeat = document.getElementById('lblFeat');
  const lblKeep = document.getElementById('lblKeep');

  const video = document.getElementById('video');
  const viewC = document.getElementById('view');
  const viewG = viewC.getContext('2d');
  const mapC  = document.getElementById('map');
  const mapG  = mapC.getContext('2d');

  rngFeat.addEventListener('input', () => lblFeat.textContent = rngFeat.value);
  rngKeep.addEventListener('input', () => lblKeep.textContent = rngKeep.value);

  // State
  let stream = null;
  let running = false;
  let rafId = null;

  // OpenCV objects
  let cvReady = false;
  let cap = null;

  // Frame buffers
  let matRGBA = null, matGray = null;
  let prevGray = null;

  // Feature & matching
  let orb = null;
  let bf = null;
  let prevKp = null, prevDesc = null;

  // Pose (world)
  // We keep a 3x3 rotation R and 3x1 position p in "arbitrary units"
  let Rw = null; // 3x3 CV_64F
  let pw = null; // 3x1 CV_64F

  // Map
  const traj = [];      // [{x,z}]
  const mapPts = [];    // [{x,z}]
  const MAX_MAP_PTS = 3000;

  // Parameters
  function maxFeatures(){ return parseInt(rngFeat.value, 10); }
  function keepMatches(){ return parseInt(rngKeep.value, 10); }

  function logStatus(lines){
    statusEl.textContent = lines.join('\n');
  }

  function resetMap(){
    traj.length = 0;
    mapPts.length = 0;
    // Identity rotation, zero position
    if (Rw) Rw.delete();
    if (pw) pw.delete();
    Rw = cv.Mat.eye(3,3,cv.CV_64F);
    pw = new cv.Mat(3,1,cv.CV_64F);
    pw.data64F[0] = 0; pw.data64F[1] = 0; pw.data64F[2] = 0;
    traj.push({x:0, z:0});
    drawMap();
  }

  function drawMap(){
    // background
    mapG.clearRect(0,0,mapC.width,mapC.height);
    mapG.fillStyle = '#0b0b0b';
    mapG.fillRect(0,0,mapC.width,mapC.height);

    // axes
    mapG.strokeStyle = 'rgba(255,255,255,0.08)';
    mapG.beginPath();
    mapG.moveTo(mapC.width/2, 0);
    mapG.lineTo(mapC.width/2, mapC.height);
    mapG.moveTo(0, mapC.height/2);
    mapG.lineTo(mapC.width, mapC.height/2);
    mapG.stroke();

    // auto scale by trajectory extent
    let minX=0, maxX=0, minZ=0, maxZ=0;
    for (const p of traj){
      if (p.x < minX) minX=p.x; if (p.x > maxX) maxX=p.x;
      if (p.z < minZ) minZ=p.z; if (p.z > maxZ) maxZ=p.z;
    }
    const spanX = Math.max(1e-6, (maxX-minX));
    const spanZ = Math.max(1e-6, (maxZ-minZ));
    const span = Math.max(spanX, spanZ);
    const margin = 0.15;
    const scale = (mapC.width * (1 - margin*2)) / span;

    const cx = mapC.width/2;
    const cz = mapC.height/2;

    function toPix(x,z){
      return {
        x: cx + x*scale,
        y: cz + z*scale
      };
    }

    // map points
    mapG.fillStyle = 'rgba(200,200,200,0.45)';
    const step = Math.max(1, Math.floor(mapPts.length / 1200)); // decimate draw
    for (let i=0;i<mapPts.length;i+=step){
      const p = mapPts[i];
      const q = toPix(p.x, p.z);
      mapG.fillRect(q.x, q.y, 1, 1);
    }

    // trajectory
    mapG.strokeStyle = 'rgba(120,170,255,0.95)';
    mapG.lineWidth = 2;
    mapG.beginPath();
    for (let i=0;i<traj.length;i++){
      const p = toPix(traj[i].x, traj[i].z);
      if (i===0) mapG.moveTo(p.x,p.y);
      else mapG.lineTo(p.x,p.y);
    }
    mapG.stroke();

    // current position marker
    const last = traj[traj.length-1];
    const m = toPix(last.x,last.z);
    mapG.fillStyle = 'rgba(120,170,255,1)';
    mapG.beginPath();
    mapG.arc(m.x, m.y, 4, 0, Math.PI*2);
    mapG.fill();
  }

  // Helpers for CV_64F mats (3x3, 3x1)
  function matMul3x3(A,B){
    const C = new cv.Mat(3,3,cv.CV_64F);
    for (let r=0;r<3;r++){
      for (let c=0;c<3;c++){
        let s=0;
        for (let k=0;k<3;k++) s += A.data64F[r*3+k]*B.data64F[k*3+c];
        C.data64F[r*3+c]=s;
      }
    }
    return C;
  }
  function matMul3x3Vec(A,v){ // v:3x1
    const out = new cv.Mat(3,1,cv.CV_64F);
    for (let r=0;r<3;r++){
      out.data64F[r] = A.data64F[r*3+0]*v.data64F[0] + A.data64F[r*3+1]*v.data64F[1] + A.data64F[r*3+2]*v.data64F[2];
    }
    return out;
  }
  function matAdd3(a,b){
    const out = new cv.Mat(3,1,cv.CV_64F);
    out.data64F[0]=a.data64F[0]+b.data64F[0];
    out.data64F[1]=a.data64F[1]+b.data64F[1];
    out.data64F[2]=a.data64F[2]+b.data64F[2];
    return out;
  }
  function matScale3(v,s){
    const out = new cv.Mat(3,1,cv.CV_64F);
    out.data64F[0]=v.data64F[0]*s;
    out.data64F[1]=v.data64F[1]*s;
    out.data64F[2]=v.data64F[2]*s;
    return out;
  }

  // Camera intrinsics (rough). We approximate fx, fy from image width/height.
  function makeK(w,h){
    const fx = 0.9*w;
    const fy = 0.9*w; // assume square pixels
    const cx = w/2;
    const cy = h/2;
    const K = cv.matFromArray(3,3,cv.CV_64F, [
      fx, 0, cx,
      0, fy, cy,
      0, 0, 1
    ]);
    return K;
  }

  function start(){
    if (!cvReady) return;
    if (running) return;
    running = true;

    btnStart.disabled = true;
    btnStop.disabled = false;
    btnReset.disabled = false;

    resetMap();

    prevGray?.delete?.(); prevGray = null;
    prevKp?.delete?.(); prevKp = null;
    prevDesc?.delete?.(); prevDesc = null;

    loop();
  }

  function stop(){
    running = false;
    btnStart.disabled = false;
    btnStop.disabled = true;
    // keep reset enabled
    if (rafId) cancelAnimationFrame(rafId);
    rafId = null;
  }

  async function initCamera(){
    stream = await navigator.mediaDevices.getUserMedia({
      video: { width: { ideal: 960 }, height: { ideal: 540 }, facingMode: "environment" },
      audio: false
    });
    video.srcObject = stream;
    await video.play();
    // resize canvas to video
    const w = video.videoWidth || 960;
    const h = video.videoHeight || 540;
    viewC.width = w;
    viewC.height = h;

    // init mats/capture
    cap = new cv.VideoCapture(video);
    matRGBA = new cv.Mat(h, w, cv.CV_8UC4);
    matGray = new cv.Mat(h, w, cv.CV_8UC1);

    // ORB / matcher
    orb = new cv.ORB(maxFeatures(), 1.2, 8, 31, 0, 2, cv.ORB_HARRIS_SCORE, 31, 20);
    bf = new cv.BFMatcher(cv.NORM_HAMMING, false);

    logStatus([
      'Ready.',
      `Video: ${w}x${h}`,
      'Press Start.'
    ]);
  }

  function cleanup(){
    stop();
    if (stream){
      for (const t of stream.getTracks()) t.stop();
      stream = null;
    }
    if (cap) { cap = null; }
    [matRGBA, matGray, prevGray, prevKp, prevDesc, orb, bf, Rw, pw].forEach(x => { try { x && x.delete(); } catch(e){} });
    matRGBA = matGray = prevGray = prevKp = prevDesc = orb = bf = Rw = pw = null;
  }

  function loop(){
    if (!running) return;
    rafId = requestAnimationFrame(loop);

    // Update ORB params live (recreate ORB if needed)
    const desired = maxFeatures();
    if (orb && orb.getMaxFeatures && orb.getMaxFeatures() !== desired){
      orb.delete();
      orb = new cv.ORB(desired, 1.2, 8, 31, 0, 2, cv.ORB_HARRIS_SCORE, 31, 20);
    }

    cap.read(matRGBA);
    cv.cvtColor(matRGBA, matGray, cv.COLOR_RGBA2GRAY);

    // detect + compute
    const kp = new cv.KeyPointVector();
    const desc = new cv.Mat();
    orb.detectAndCompute(matGray, new cv.Mat(), kp, desc);

    // draw camera image
    viewG.drawImage(video, 0, 0, viewC.width, viewC.height);

    // feature overlay
    viewG.save();
    viewG.fillStyle = 'rgba(120,255,160,0.9)';
    const nKp = kp.size();
    const stride = Math.max(1, Math.floor(nKp / 800));
    for (let i=0;i<nKp;i+=stride){
      const p = kp.get(i).pt;
      viewG.fillRect(p.x-1, p.y-1, 2, 2);
    }
    viewG.restore();

    let info = [
      `Features: ${nKp}`,
      `Matches kept: ${keepMatches()}`,
      `Trajectory points: ${traj.length}`,
      `Map points: ${mapPts.length}`
    ];

    if (prevGray && prevDesc && !prevDesc.empty() && !desc.empty()){
      // match
      const matches = new cv.DMatchVector();
      bf.match(prevDesc, desc, matches);

      // sort by distance
      const mArr = [];
      for (let i=0;i<matches.size();i++){
        const m = matches.get(i);
        mArr.push({ q: m.queryIdx, t: m.trainIdx, d: m.distance });
      }
      mArr.sort((a,b)=>a.d-b.d);
      const K = Math.min(keepMatches(), mArr.length);

      if (K >= 80){
        // build point arrays
        const pts1 = [];
        const pts2 = [];
        for (let i=0;i<K;i++){
          const m = mArr[i];
          const p1 = prevKp.get(m.q).pt;
          const p2 = kp.get(m.t).pt;
          pts1.push(p1.x, p1.y);
          pts2.push(p2.x, p2.y);
        }
        const m1 = cv.matFromArray(K,1,cv.CV_32FC2, pts1);
        const m2 = cv.matFromArray(K,1,cv.CV_32FC2, pts2);

        // estimate pose
        const Kmat = makeK(viewC.width, viewC.height);
        const mask = new cv.Mat();

        // RANSAC Essential
        const E = cv.findEssentialMat(m1, m2, Kmat, cv.RANSAC, 0.999, 1.0, mask);

        if (!E.empty()){
          const R = new cv.Mat();
          const t = new cv.Mat();
          const inliers = cv.recoverPose(E, m1, m2, Kmat, R, t, mask);

          // Update world pose:
          // world_R = world_R * R
          // world_p = world_p + world_R * (t * scale)
          // (scale is arbitrary; we just use a constant step)
          const stepScale = 0.08; // tune: bigger => faster movement on map
          const t64 = new cv.Mat(3,1,cv.CV_64F);
          t64.data64F[0] = t.data64F ? t.data64F[0] : t.data32F[0];
          t64.data64F[1] = t.data64F ? t.data64F[1] : t.data32F[1];
          t64.data64F[2] = t.data64F ? t.data64F[2] : t.data32F[2];

          // Rw_new = Rw * R
          const RwNew = matMul3x3(Rw, R);

          // dp_world = Rw * (t * scale)  (use previous Rw for increment)
          const tScaled = matScale3(t64, stepScale);
          const dpWorld = matMul3x3Vec(Rw, tScaled);
          const pwNew = matAdd3(pw, dpWorld);

          // commit
          Rw.delete(); pw.delete();
          Rw = RwNew; pw = pwNew;

          // record trajectory: use x,z (ignore y)
          traj.push({ x: pw.data64F[0], z: pw.data64F[2] });

          // add some "map points": take some inlier correspondences and drop points around current pose
          // (This is not true triangulation; it's a lightweight "map-ish" sprinkle for demo)
          // We bias points forward of the camera based on feature x position.
          const addEvery = Math.max(2, Math.floor(K / 120));
          for (let i=0;i<K;i+=addEvery){
            // if inlier
            if (mask.dataU8[i] === 0) continue;
            const x = m2.data32F[i*2+0];
            const y = m2.data32F[i*2+1];
            // normalized image coords (rough)
            const nx = (x - viewC.width/2) / (viewC.width/2);
            const nz = 1.0; // forward
            const spread = 0.25;
            const px = pw.data64F[0] + nx * spread;
            const pz = pw.data64F[2] + nz * spread;
            mapPts.push({x:px, z:pz});
          }
          if (mapPts.length > MAX_MAP_PTS) mapPts.splice(0, mapPts.length - MAX_MAP_PTS);

          drawMap();

          info.push(`Inliers: ${inliers}`);
          info.push(`Pose stepScale: ${stepScale}`);
          R.delete(); t.delete(); t64.delete(); tScaled.delete(); dpWorld.delete();
        } else {
          info.push('Pose: failed (E empty)');
        }

        // draw match lines sparsely
        viewG.save();
        viewG.strokeStyle = 'rgba(255,255,255,0.10)';
        viewG.lineWidth = 1;
        const drawN = Math.min(80, K);
        for (let i=0;i<drawN;i++){
          const m = mArr[i];
          const p1 = prevKp.get(m.q).pt;
          const p2 = kp.get(m.t).pt;
          viewG.beginPath();
          viewG.moveTo(p1.x, p1.y);
          viewG.lineTo(p2.x, p2.y);
          viewG.stroke();
        }
        viewG.restore();

        // cleanup
        E.delete(); mask.delete(); m1.delete(); m2.delete(); Kmat.delete();
      } else {
        info.push(`Pose: not enough matches (${K})`);
      }

      matches.delete();
    } else {
      info.push('Pose: waiting for previous frame...');
    }

    logStatus(info);

    // swap prev
    if (prevGray) prevGray.delete();
    prevGray = matGray.clone();

    if (prevKp) prevKp.delete();
    prevKp = kp;

    if (prevDesc) prevDesc.delete();
    prevDesc = desc;
    // keep kp, desc
    // cleanup temp:
    // (kp is stored as prevKp, desc as prevDesc)
  }

  // OpenCV ready hook
  window.Module = window.Module || {};
  window.Module.onRuntimeInitialized = async () => {
    cvReady = true;
    logStatus(['OpenCV.js loaded.', 'Requesting camera permission...']);
    try{
      await initCamera();
      btnStart.disabled = false;
    }catch(e){
      logStatus(['Camera init failed:', String(e)]);
    }
  };

  btnStart.addEventListener('click', start);
  btnStop.addEventListener('click', stop);
  btnReset.addEventListener('click', resetMap);

  window.addEventListener('beforeunload', cleanup);
})();
</script>
</body>
</html>
